{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JSON\n",
    "using LinearAlgebra\n",
    "using SparseArrays\n",
    "using StatsBase\n",
    "using Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some conceptual background\n",
    "\n",
    "Covariance estimation is challenging, and the difficulty increases with the dimension of the data.\n",
    "\n",
    "However, consider this unusual situation:\n",
    "\n",
    "* We assume the precision matrix (inverse covariance matrix) \\\\( \\Omega \\\\) is a linear combination of sparse symmetric positive definite *basis matrices* \\\\(\\Omega_1, \\ldots, \\Omega_k\\\\).\n",
    "* We assume the sparse precision matrices \\\\(\\Omega_1, \\ldots, \\Omega_K\\\\) have little off-diagonal \"overlap\" with each other. I.e., there exist relatively few indices \\\\( (i,j) \\\\) such that multiple basis matrices have nonzero entries at \\\\( (i,j) \\\\).\n",
    "\n",
    "In this special case, covariance estimation reduces to finding \\\\( \\alpha_1, \\ldots, \\alpha_K \\\\), the coefficients of the linear combination \\\\( \\Omega = \\sum_k \\alpha_k \\Omega_k \\\\). \n",
    "\n",
    "Furthermore: under these circumstances, increasing the dimension of the data actually *improves* our ability to estimate covariance. Each new dimension yields more information about the relative contributions of the different basis matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwys = JSON.parsefile(\"../analyses/temp/pathways/TCGA.json\");\n",
    "data = JSON.parsefile(\"../analyses/temp/experimental_eval/data/TCGA.json\");\n",
    "pattern = JSON.parsefile(\"../analyses/temp/experimental_eval/observations/pwys=TCGA__test=0.1__rep=0.json\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data to matrices: observed and hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix = transpose(hcat(data[\"data\"]...))\n",
    "obs_idx = pattern[\"measured_train\"]\n",
    "observed_data = data_matrix[:, obs_idx]\n",
    "obs_idx_set = Set(obs_idx)\n",
    "\n",
    "hidden_idx = [idx for idx=1:size(data_matrix,2) if !( idx in obs_idx_set )]\n",
    "hidden_data = 0.01 * randn(size(data_matrix,1), size(data_matrix,2) - size(obs_idx,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the pathways to matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Approximate) Method of Moments\n",
    "\n",
    "If we try a Maximum Likelihood approach, we end up with this mystifying first-order-sufficient condition:\n",
    "\n",
    "\\\\( \\sum_{m,n} \\left[ (\\sum_k \\alpha_k \\Omega_k )^{-1} \\right]_{m,n} \\cdot \\left[ \\Omega_i \\right]_{m,n} = x^T \\Omega_i x ~ ~ \\forall i \\in [K] \\\\)\n",
    "\n",
    "This is satisfied if \n",
    "\n",
    "\\\\( (\\sum_k \\alpha_k \\Omega_k )^{-1} = x x^T\\\\).\n",
    "\n",
    "However, it isn't straightforward to find the \\\\(\\alpha_k \\\\) satisfying that expression.\n",
    "Solving it via gradient descent would be prohibitively expensive -- computing the gradient would entail inverting a large matrix at every step.\n",
    "\n",
    "Alternatively we can convert this to a **Method of Moments** estimator by seeking \\\\( \\alpha_1, \\ldots, \\alpha_K \\\\) satisfying \n",
    "\n",
    "\\\\( \\sum_k \\alpha_k \\Omega_k  = \\left[\\lambda x x^T + (1 - \\lambda) \\sigma^2 I \\right]^{-1} \\\\)\n",
    "\n",
    "where \\\\( \\lambda \\in [0,1) \\\\). That is, we make the empirical covariance invertible and set its inverse to a linear combination of the basis matrices.\n",
    "\n",
    "We can write the inverse on the RHS in closed form:\n",
    "\n",
    "\\\\(\\frac{1}{\\sigma^2 (1 - \\lambda)} \\left[ I  - \\frac{\\lambda}{\\lambda x^\\top x + (1 - \\lambda) \\sigma^2} x x^\\top \\right]\\\\) \n",
    "\n",
    "\n",
    "The equation is unlikely to have an exact solution.\n",
    "However, we can solve it approximately in a least-squares sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's simulate some data and see how this goes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = 8000\n",
    "n_pwys = 100\n",
    "n_patients = 50\n",
    "pwy_density = 0.002;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for building a sparse, signed, undirected network (edge list)\n",
    "function build_sparse_network(data_dim, density)\n",
    "    n_edges = Int(round(density*data_dim*(data_dim - 1)*0.5))\n",
    "    edges = Set{Pair{Int64,Int64}}()\n",
    "    result = zeros(Int64, n_edges, 3)\n",
    "    row = 1\n",
    "    while row <= n_edges\n",
    "        pair = collect(samplepair(data_dim))\n",
    "        sort!(pair)\n",
    "        pair_pair = (pair[1] => pair[2])\n",
    "        if !(pair_pair in edges)\n",
    "            push!(edges, pair[1] => pair[2])\n",
    "            sgn = rand([-1,1])\n",
    "            result[row,:] .= [pair[1], pair[2], sgn]\n",
    "            row = row + 1\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return result\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a list (\"basis\") of sparse, undirected networks\n",
    "networks = [build_sparse_network(data_dim, pwy_density) for i=1:n_pwys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some \"pathway activations\"\n",
    "activations = rand(Distributions.Exponential(1.0), n_pwys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a big fat precision matrix\n",
    "off_diag_multiplier = 1.0\n",
    "diag_multiplier = 200.0\n",
    "\n",
    "function build_precision_matrix(networks, activations, data_dim)\n",
    "    \n",
    "    combined_edges = Set{Pair{Int64,Int64}}()\n",
    "    for net in networks\n",
    "        for i=1:size(net,1)\n",
    "            push!(combined_edges, net[i,1] => net[i,2])\n",
    "        end\n",
    "    end\n",
    "    encoder = collect(combined_edges)\n",
    "    decoder = Dict([edge => i for (i, edge) in enumerate(encoder)])\n",
    "    \n",
    "    result_I = [edge.first for edge in encoder]\n",
    "    result_J = [edge.second for edge in encoder]\n",
    "    result_V = zeros(length(encoder))\n",
    "    \n",
    "    for (i, net) in enumerate(networks)\n",
    "        for j=1:size(net,1)\n",
    "            edge = (net[j,1] => net[j,2])\n",
    "            result_idx = decoder[edge]\n",
    "            result_V[result_idx] += net[j,3]*activations[i]*off_diag_multiplier\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    result = Symmetric(sparse(result_I, result_J, result_V, data_dim, data_dim) + sparse(I,data_dim,data_dim)*diag_multiplier)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = build_precision_matrix(networks, activations, data_dim)\n",
    "# prec = prec + 200.0*sparse(I,dim,dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample some data from a MVN, parameterized by the big fat precision matrix\n",
    "F = cholesky(prec)\n",
    "z = randn(data_dim, n_patients)\n",
    "\n",
    "X = F.UP\\z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the matrix of precision matrix entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function build_regression_features(networks)\n",
    "    result = Dict{Pair{Int64,Int64},Vector{Float64}}()\n",
    "    for (i,net) in enumerate(networks)\n",
    "        for j=1:size(net,1)\n",
    "            if net[j,1] == net[j,2]\n",
    "                continue\n",
    "            end\n",
    "            edgepair = net[j,1]=>net[j,2]\n",
    "            if !(edgepair in keys(result))\n",
    "                result[edgepair] = zeros(size(networks,1))\n",
    "            end\n",
    "            result[edgepair][i] = net[j,3]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    result_idx = collect(keys(result))\n",
    "    result_mat = zeros(length(result_idx),size(networks,1))\n",
    "    for i=1:size(result_mat,1)\n",
    "        result_mat[i,:] .= result[result_idx[i]]\n",
    "    end\n",
    "    return result_idx, result_mat\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_feat_idx, reg_feat = build_regression_features(networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute entries of the empirical precision matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_empirical_prec(i, j, x, lambda, sigma_sq, denom, normsq)\n",
    "    result =  -lambda * x[i]*x[j] / (lambda*normsq + denom)\n",
    "    if i == j\n",
    "        result += 1.0\n",
    "    end\n",
    "    return result/denom\n",
    "end\n",
    "\n",
    "function build_regression_target(reg_feat_idx, X, lambda, sigma_sq)\n",
    "    result = zeros(size(reg_feat_idx,1), size(X,2))\n",
    "    denom = (1.0 - lambda) * sigma_sq\n",
    "    for j=1:size(X,2)\n",
    "        normsq = dot(X[:,j],X[:,j])\n",
    "        big_mult = -lambda /(lambda*normsq + denom)\n",
    "        for (i,p) in enumerate(reg_feat_idx)\n",
    "            result[i,j] = big_mult * X[p.first,j] * X[p.second,j]\n",
    "        end\n",
    "    end\n",
    "    return result\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vector of precision matrix entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda = 0.5\n",
    "sigma_sq = 1.0\n",
    "B = build_regression_target(reg_feat_idx, X, lambda, sigma_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = transpose(reg_feat) * B\n",
    "regularized = transpose(reg_feat)*reg_feat + 100000.0*I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = reg_feat \\ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularized_pred = regularized \\ Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [corspearman(pred[:,i], activations) for i=1:n_patients]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularized_scores = [corspearman(regularized_pred[:,i], activations) for i=1:n_patients]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(regularized_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
